#!/bin/bash

# ===========================================================================
#
#                            PUBLIC DOMAIN NOTICE
#            National Center for Biotechnology Information (NCBI)
#
#  This software/database is a "United States Government Work" under the
#  terms of the United States Copyright Act.  It was written as part of
#  the author's official duties as a United States Government employee and
#  thus cannot be copyrighted.  This software/database is freely available
#  to the public for use. The National Library of Medicine and the U.S.
#  Government do not place any restriction on its use or reproduction.
#  We would, however, appreciate having the NCBI and the author cited in
#  any work or product based on this material.
#
#  Although all reasonable efforts have been taken to ensure the accuracy
#  and reliability of the software and data, the NLM and the U.S.
#  Government do not and cannot warrant the performance or results that
#  may be obtained by using this software or data. The NLM and the U.S.
#  Government disclaim all warranties, express or implied, including
#  warranties of performance, merchantability or fitness for any particular
#  purpose.
#
# ===========================================================================
#
# File Name:  xbuild
#
# Author:  Jonathan Kans, Aaron Ucko
#
# Version Creation Date:   07/14/2025
#
# ==========================================================================

# environment variable turns on shell tracing

if [ -n "${EDIRECT_TRACE}" ] && [ "${EDIRECT_TRACE}" = true ]
then
  set -x
fi

# initialize common flags

total_start=$(date "+%s")

osname=$( uname -s | sed -e 's/_NT-.*$/_NT/; s/^MINGW[0-9]*/CYGWIN/' )

dbase=""
project=""

folder=""

custom=""

step=""

archiveBase=""
sentinelsBase=""
dataBase=""
postingsBase=""
sourceBase=""
extrasBase=""
indexBase=""
invertBase=""
mergedBase=""
scratchBase=""
currentBase=""
indexedBase=""
invertedBase=""

localPaths=""

edirectBase=""
externBase=""

# control flags set by command-line arguments

useFtp=true
useHttps=false
noAspera=false
transportProtocol=""

info=false

check=true

datafiles=true
download=true
generate=true
populate=true

e2index=false
e2invert=false
e2collect=false
e2merge=false
e2post=false

darkMode=false
darkFlag=""

logMode=false

level=""

success=false

DAT=""
DWN=""
GEN=""
POP=""

IDX=""
INV=""
COL=""
MRG=""
PST=""

# set up colors for error report

ColorSetup() {

  if [ -z "$TERM" ] || [ ! -t 2 ]
  then
    RED=""
    BLUE=""
    BOLD=""
    FLIP=""
    INIT=""
  elif command -v tput >/dev/null
  then
    RED="$(tput setaf 1)"
    BLUE="$(tput setaf 4)"
    BOLD="$(tput bold)"
    FLIP="$(tput rev)"
    INIT="$(tput sgr0)"
  else
    # assume ANSI
    escape="$(printf '\033')"
    RED="${escape}[31m"
    BLUE="${escape}[34m"
    BOLD="${escape}[1m"
    FLIP="${escape}[7m"
    INIT="${escape}[0m"
  fi
  LOUD="${INIT}${RED}${BOLD}"
  INVT="${LOUD}${FLIP}"
  # clear color on terminal if "export EDIRECT_TRACE=true" has been used
  echo "${INIT}" > /dev/null
}

ColorSetup

# highlighted error and warning functions

DisplayError() {

  if [ $# -gt 0 ]
  then
    msg="$1"
    echo "${INVT} ERROR: ${LOUD} ${msg}${INIT}" >&2
  fi
}

DisplayWarning() {

  if [ $# -gt 0 ]
  then
    msg="$1"
    echo "${INVT} WARNING: ${LOUD} ${msg}${INIT}" >&2
  fi
}

DisplayNote() {

  if [ $# -gt 0 ]
  then
    msg="$1"
    echo "${INVT} NOTE: ${LOUD} ${msg}${INIT}" >&2
  fi
}

DisplayLog() {

  if [ $# -gt 0 ]
  then
    msg="$1"
    echo "${INVT} LOG: ${LOUD} ${msg}${INIT}" >&2
  fi
}

# get paths to edirect and extern folders

hasxtract=$( command -v xtract )
if [ -x "$hasxtract" ]
then
  edirectBase=${hasxtract%/*}
  externBase="${edirectBase}/extern"
fi

if [ -z "$edirectBase" ] || [ "$edirectBase" = "" ] || [ ! -d "$edirectBase" ]
then
  DisplayError "Unable to find database-specific archive scripts."
  exit 1
fi

# parse ConfigFile XML object

ParseConfig() {

  mesg=$1
  objc=$2
  shift 2

  if [ -z "$mesg" ]
  then
    return 1
  fi

  while [ $# -gt 0 ]
  do
    var=$1
    fld=$2
    shift 2
    value=$( echo "$mesg" | xtract -pattern Rec -ret "" -element "$fld" )
    if [ -n "$value" ]
    then
      eval "$var=\$value"
    fi
  done

  return 0
}

# parse ArchivePaths XML object returned by rchive -local

ParseArchivePaths() {

  mesg=$1
  objc=$2
  shift 2

  if [ -z "$mesg" ]
  then
    return 1
  fi

  object=$( echo "$mesg" | tr -d '\n' | sed -n "s|.*<$objc>\\(.*\\)</$objc>.*|\\1|p" )
  if [ -z "$object" ]
  then
    return 2
  fi

  while [ $# -gt 0 ]
  do
    var=$1
    fld=$2
    shift 2
    value=$( echo "$object" | sed -n "s|.*<$fld>\\(.*\\)</$fld>.*|\\1|p" )
    if [ -n "$value" ]
    then
      if [ -n "$osname" ] && [ "$osname" = "CYGWIN_NT" -a -x /bin/cygpath ]
      then
        value=$( cygpath -w "$value" )
      fi

      # remove trailing slash
      value=${value%/}

      eval "$var=\$value"
    fi
  done

  return 0
}

# process common control flags

CheckForArgumentValue() {

  tag="$1"
  rem="$2"

  if [ "$rem" -lt 2 ]
  then
    DisplayError "Missing ${tag} argument"
    exit 1
  fi
}

# read command line arguments, set dbase and folder variables

while [ $# -gt 0 ]
do
  tag="$1"
  rem="$#"
  case "$tag" in

    -db | -dbase )
      CheckForArgumentValue "$tag" "$rem"
      shift
      dbase="$1"
      shift
      ;;
    -project )
      CheckForArgumentValue "$tag" "$rem"
      shift
      project="$1"
      shift
      ;;

    -clean | -clear | -scrap | -scrub | -scour | -erase | -zap )
      level="$1"
      # remove leading hyphen
      level="${level:1}"
      shift
      ;;

    -info )
      info=true
      shift
      ;;

    -daily )
      e2index=true
      e2invert=true
      datafiles=true
      shift
      ;;
    -index | -reindex )
      e2index=true
      e2invert=true
      e2collect=true
      e2merge=true
      e2post=true
      datafiles=true
      shift
      ;;

    -ftp )
      useFtp=true
      useHttps=false
      noAspera=true
      transportProtocol="$tag"
      export EDIRECT_NO_ASPERA=true
      shift
      ;;
    -http | -https )
      useFtp=false
      useHttps=true
      transportProtocol="$tag"
      shift
      ;;

    -step )
      CheckForArgumentValue "$tag" "$rem"
      shift
      step="$1"
      shift
      ;;

    -dark )
      darkMode=true
      darkFlag="$1"
      shift
      ;;
    -log )
      logMode=true
      shift
      ;;

    -custom )
      CheckForArgumentValue "$tag" "$rem"
      shift
      custom="$1"
      shift
      ;;

    -* )
      DisplayError "'$1' is not a recognized command"
      exit 1
      ;;
    * )
      DisplayError "'$1' is not a recognized option"
      exit 1
      ;;
  esac
done

if [ -z "$dbase" ] || [ "$dbase" = "" ]
then
  DisplayError "Missing -db argument"
  exit 1
fi

if [ -z "$project" ] || [ "$project" = "" ]
then
  # default to extern folder with same name as database
  project="$dbase"
fi

# set project folder within extern directory

if [ "$project" = "$dbase" ]
then
  # primary database
  folder="${dbase}"
else
  # secondary project
  folder="${dbase}-${project}"
fi

if [ -z "$folder" ] || [ "$folder" = "" ]
then
  DisplayError "Project folder is not set"
  exit 1
fi

# read project-specific configuration file

if [ ! -f "${externBase}/${folder}/${project}.ini" ]
then
  DisplayError "Missing ${project}.ini configuration file"
  exit 1
fi

config=$( cat "${externBase}/${folder}/${project}.ini" | ini2xml )

if [ -z "$config" ] || [ "$config" = "" ]
then
  DisplayError "Unable to read ${project}.ini configuration file"
  exit 1
fi

# -dark mode skips all steps that download data from the network

if [ "$darkMode" = true ]
then
  # suppress all steps with obligatory network access
  info=false
  check=false
  datafiles=false
  download=false
fi

# all but original pubmed and pmc archives need Go compiler installed

needsGoCompiler=false

if [ "$project" != "pubmed" ] && [ "$project" != "pmc" ]
then
  needsGoCompiler=true
elif [ "$project" != "$dbase" ]
then
  needsGoCompiler=true
fi

if [ "$needsGoCompiler" = true ]
then
  hasgo=$( command -v go )
  if [ ! -x "$hasgo" ]
  then
    DisplayError "The Go (golang) compiler must be installed locally in order to process $project data. EXITING"
    exit 1
  fi
fi

# set paths to all local archive folders

localPaths=$( rchive -local "$dbase" )

if [ -z "$localPaths" ] || [ "$localPaths" = "" ]
then
  DisplayError "Must supply path to local data by setting EDIRECT_LOCAL_ARCHIVE environment variable. EXITING"
  exit 1
fi

ParseArchivePaths "$localPaths" ArchivePaths \
  archiveBase "Archive" \
  sentinelsBase "Sentinels" \
  dataBase "Data" \
  postingsBase "Postings" \
  sourceBase "Source" \
  extrasBase "Extras" \
  indexBase "Index" \
  invertBase "Invert" \
  mergedBase "Merged" \
  scratchBase "Scratch" \
  currentBase "Current" \
  indexedBase "Indexed" \
  invertedBase "Inverted"

if [ "$logMode" = true ]
then
  DisplayLog "DBASE $dbase, PROJECT $project"
fi

# check for archive cleaning and indexing command collision

if [ -n "$level" ] && [ "$e2index" = true ]
then
  DisplayError "Cleaning and indexing must be done in separate commands. EXITING"
  exit 1
fi

# common local archive SSD preparation

SetupFoldersAndPrepareDrives() {

  dbs="$1"

  pm-setup -db "$dbs"

  echo "Preparing Drives" >&2

  pm-prepare -db "$dbs"
}

# execute cleaning command if requested

if [ -n "$level" ]
then
  pm-clean -db "$dbase" -project "$project" -level "$level"
  exit 0
fi

# run step if command-specific helper function is present

RunLocalArchiveStep() {

  lbl="$1"
  flg="$2"
  dir="$3"
  trg="$4"
  cmd="$5"
  sct="$6"
  msg="$7"

  if [ "$logMode" = true ]
  then
    DisplayLog "$lbl"
  fi

  # -step overrides any other setting
  if [ -n "$step" ]
  then
    if [ "$step" = "$lbl" ]
    then
      flg=true
    else
      flg=false
    fi
  fi

  # clear variables to be loaded from configuration file section

  fields=""
  isLink=false
  uid=""
  query=""
  target=""
  expect=""
  success=""
  dots=""

  linkFlag=""

  if [ "$flg" = true ] && [ -d "$dir" ]
  then

    seconds_start=$(date "+%s")

    printTime=false

    # extract configuration file section

    cfgMssg=$( echo "$config" | xtract -rec Rec -pattern "ConfigFile/*" -select "$sct" | tr '\n' ' ' )

    # parse configuration values into variables

    if [ -n "$cfgMssg" ]
    then
      # in ParseConfig argument pairs, script variable name is first, configuration item name is second
      ParseConfig "$cfgMssg" Rec \
        isLink link \
        fields fields \
        uid uid \
        query query \
        target target \
        expect expect \
        success success \
        dots dots
    fi

    if [ "$isLink" = true ]
    then
      linkFlag="-link"
    fi

    # check to see if helper file exists

    if [ -f "${externBase}/${folder}/${cmd}-${project}" ]
    then

      if [ "$logMode" = true ]
      then
        DisplayLog "$lbl using ${externBase}/${folder}/${cmd}-${project}"
      fi

      printTime=true

      echo "$msg" >&2

      # if command is in folder, construct and execute local archive build step
      case "$cmd" in
        check | datafiles | download )
          res=$( rcommon.sh -db "$dbase" -project "$project" -helper "${externBase}/${folder}/${cmd}-${project}" "$transportProtocol" -custom "$custom" -step "$step" )
          if [ -n "$res" ] && [ "$res" != "0" ]
          then
            echo "" >&2
            DisplayError "Unable to proceed with mixture of releases, run -zap command first"
            echo "" >&2
            exit 1
          fi
          ;;
        index )
          if [ -z "$dots" ] || [ "$dots" = "0" ]
          then
            dots="1000"
          fi
          if [ "$project" != "$dbase" ]
          then
            # free previous non-incremental indexed files
            cd "${dir}"
            rm -f *.e2x.gz
          fi
          cd "${dir}"
          # allow [index] fields entry for optional fields to index
          rcommon.sh -db "$dbase" -project "$project" -helper "${externBase}/${folder}/${cmd}-${project}" "$darkFlag" -dots "$dots" -fields "$fields" -custom "$custom" -step "$step"
          ;;
        invert )
          if [ -z "$dots" ] || [ "$dots" = "0" ]
          then
            dots="30"
          fi
          if [ "$project" != "$dbase" ]
          then
            # free previous non-incremental inverted index files
            cd "${trg}"
            rm -f *.inv.gz
          fi
          cd "${dir}"
          rcommon.sh -db "$dbase" -project "$project" -helper "${externBase}/${folder}/${cmd}-${project}" "$darkFlag" -dots "$dots" -custom "$custom" -step "$step"
          ;;
        merge )
          # free previous merged files
          cd "${trg}"
          rm -f *.mrg.gz
          rcommon.sh -db "$dbase" -project "$project" -helper "${externBase}/${folder}/${cmd}-${project}" "$linkFlag" "$darkFlag" -custom "$custom" -step "$step"
          ;;
        posting )
          rcommon.sh -db "$dbase" -project "$project" -helper "${externBase}/${folder}/${cmd}-${project}" "$linkFlag" "$darkFlag" -fields "$fields" -custom "$custom" -step "$step"
          ;;
        * )
          rcommon.sh -db "$dbase" -project "$project" -helper "${externBase}/${folder}/${cmd}-${project}" "$darkFlag" -custom "$custom" -step "$step"
          ;;
      esac
    else

      # otherwise use default command for latter steps

      if [ "$logMode" = true ]
      then
        DisplayLog "$lbl using built-in default command"
      fi

      case "$cmd" in
        invert )
          if [ -z "$dots" ] || [ "$dots" = "0" ]
          then
            dots="1000"
          fi
          printTime=true
          echo "$msg" >&2
          if [ "$project" = "$dbase" ]
          then
            ( rchive -db "$dbase" -dotmax "$dots" -e2incInvert "${dir}" "${trg}" )
          else
            # free previous non-incremental inverted index files
            cd "${trg}"
            rm -f *.inv.gz

            cd "${dir}"
            for fl in *.e2x.gz
            do
              base=${fl%.e2x.gz}
              echo "$base.inv"
              gunzip -c "$fl" |
              rchive -e2invert |
              gzip -1 > "${trg}/$base.inv.gz"
              sleep 1
            done
          fi
          ;;
        collect )
          if [ "$project" = "$dbase" ]
          then
            printTime=true
            echo "$msg" >&2
            # free previous collected inverted index files
            cd "${dir}"
            rm -f *.inv.gz

            idx=0
            for sub in "${invertBase}"/*
            do
              if [ -d "$sub" ]
              then
                cd "$sub"
                printf "."
                ( rchive -gzip -join *.inv.gz > "${invertBase}/${dbase}$(printf %02d $idx).inv.gz" )
                idx=$(( idx + 1 ))
              fi
            done
            printf "\n"
          fi
          ;;
        merge )
          printTime=true
          echo "$msg" >&2
          # free previous merged files
          cd "${trg}"
          rm -f *.mrg.gz
          cd "${dir}"
          if [ "$isLink" = true ]
          then
            ( rchive -gzip -db "$dbase" -link -merge "${trg}" *.inv.gz )
          else
            ( rchive -gzip -db "$dbase" -merge "${trg}" *.inv.gz )
          fi
          ;;
        posting )
          printTime=true
          echo "$msg" >&2
          cd "${dir}"
          for fl in *.mrg.gz
          do
            echo "$fl"
          done |
          sort |
          xargs -n 100 echo |
          while read files
          do
            if [ "$isLink" = true ]
            then
              ( rchive -db "$dbase" -link -promote "${trg}" "$fields" $files )
            else
              ( rchive -db "$dbase" -promote "${trg}" "$fields" $files )
            fi
          done
          ;;
        * )
          ;;
      esac
    fi

    seconds_end=$(date "+%s")
    seconds=$((seconds_end - seconds_start))

    tim="$lbl"

    if [ "$printTime" = true ]
    then
      echo "$tim $seconds seconds" >&2
      echo "" >&2

      eval "$tim=\$seconds"
    fi

    sleep 1

    # reality checks at several stages

    case "$cmd" in
      populate )
        # check for presence of UID in cache
        if [ -n "$uid" ] && [ "$uid" != "0" ] && [ -n "$expect" ]
        then
          rec=$( xfetch -db "$dbase" -id "$uid" < /dev/null | tr '\n' ' ' )
          if [ -n "$rec" ]
          then
            case "$rec" in
              *"$expect"* )
                echo "Archive is OK" >&2
                echo "" >&2
                ;;
              * )
                DisplayError "Failed to find record $uid"
                echo "" >&2
                ;;
            esac
          fi
        fi
        ;;
      merge )
        # check for last expected file name
        if [ -n "$success" ] && [ ! -f "${mergedBase}/${success}" ]
        then
          DisplayError "Merge failed to complete - missing ${success} file."
          echo "" >&2
          echo "EXITING DUE TO BUILD FAILURE" >&2
          echo "" >&2
          # do not continue
          e2post=false
        fi
        ;;
      posting )
        # check for indexed search returning UID in cache
        if [ -n "$query" ] && [ -n "$expect" ]
        then
          rec=$( xsearch -db "$dbase" -query "$query" < /dev/null | tr '\n' ' ' )
          if [ -n "$rec" ]
          then
            case "$rec" in
              *"$expect"* )
                echo "Archive and Index are OK" >&2
                echo "" >&2
                success=true
                ;;
              * )
                DisplayError "Failed to find record $uid"
                echo "" >&2
                ;;
            esac
          fi
        elif  [ -n "$uid" ] && [ "$uid" != "0" ] && [ -n "$target" ] && [ -n "$expect" ] && [ "$isLink" = true ]
        then
          rec=$( xlink -db "$dbase" -id "$uid" -target "$target" < /dev/null | tr '\n' ' ' )
          if [ -n "$rec" ]
          then
            case "$rec" in
              *"$expect"* )
                echo "Archive is OK" >&2
                echo "" >&2
                ;;
              * )
                DisplayError "Failed to find record $uid"
                echo "" >&2
                ;;
            esac
          fi
        fi
        ;;
    esac

  elif  [ "$flg" = true ]
  then
    if [ "$logMode" = true ]
    then
      DisplayLog "$lbl failed due to missing directory $dir"
    fi

  elif [ -d "$dir" ]
  then
    if [ "$logMode" = true ]
    then
      DisplayLog "$lbl step not requested"
    fi

  else
    if [ "$logMode" = true ]
    then
      DisplayLog "$lbl bypassed inexplicably"
    fi
  fi
}

echo "" >&2

# START OF INDEXING

date >&2
echo "" >&2

# prepare archive folders

if [ -z "$step" ] || [ "$step" = "SET" ]
then
  SetupFoldersAndPrepareDrives "$dbase"
fi

# info step

if [ "$info" = true ]
then
  # -info implemented by executing check-xxx script
  ignore=$( RunLocalArchiveStep "CHK" "$info" "$sourceBase" "" "check" "" "Checking for New Release" )
  if [ -n "$ignore" ] && [ "$ignore" != "0" ]
  then
    exit 1
  fi
  exit 0
fi

# -step download also exits immediately

if [ -n "$step" ] && [ "$step" = "DWN" ]
then
  RunLocalArchiveStep "DWN" "$download" "$sourceBase" "" "download" "" "Downloading Release Files"
  exit 0
fi

# proceed with indexing steps

RunLocalArchiveStep "DAT" "$datafiles" "$extrasBase" "" "datafiles" "" "Downloading Data Files"

RunLocalArchiveStep "DWN" "$download" "$sourceBase" "" "download" "" "Downloading Release Files"

RunLocalArchiveStep "GEN" "$generate" "$extrasBase" "" "generate" "" "Generating Records"

RunLocalArchiveStep "POP" "$populate" "$extrasBase" "" "populate" "archive" "Populating Archive"

if [ "$project" = "$dbase" ]
then
  RunLocalArchiveStep "IDX" "$e2index" "$indexBase" "" "index" "index" "Incremental Indexing"
else
  RunLocalArchiveStep "IDX" "$e2index" "$indexedBase" "" "index" "index" "Indexing Records"
fi

if [ "$project" = "$dbase" ]
then
  RunLocalArchiveStep "INV" "$e2invert" "$indexBase" "$invertBase" "invert" "invert" "Incremental Inversion"
else
  RunLocalArchiveStep "INV"  "$e2invert" "$indexedBase" "$invertedBase" "invert" "invert" "Inverting Indices"
fi

if [ "$project" = "$dbase" ]
then
  RunLocalArchiveStep "COL" "$e2collect" "$invertBase" "" "collect" "collect" "Collect Inverted Sets"
else
  RunLocalArchiveStep "COL" "$e2collect" "$invertedBase" "" "collect" "collect" "Collect Inverted Sets"
fi

if [ "$project" = "$dbase" ]
then
  RunLocalArchiveStep "MRG" "$e2merge" "$invertBase" "$mergedBase" "merge" "merge" "Merging Inverted Indices"
else
  RunLocalArchiveStep "MRG" "$e2merge" "$invertedBase" "$mergedBase" "merge" "merge" "Merging Inverted Indices"
fi

RunLocalArchiveStep "PST" "$e2post" "$mergedBase" "$postingsBase" "posting" "posting" "Producing Postings File"

# cleanup of intermediate files on success

if [ "$e2post" = true ] && [ -n "$success" ] && [ -d "${mergedBase}" ] && [ -z "$step" ]
then
  find "${mergedBase}" -name "*.mrg" -delete
  find "${mergedBase}" -name "*.mrg.gz" -delete

  if [ -d "${invertBase}" ] && [ "$project" = "$dbase" ]
  then
    cd "${invertBase}"
    rm -f *.inv.gz
  fi
fi

# end of indexing

cd

if [ -z "$step" ]
then

  prjct=$(echo "$project" | tr '[:lower:]' '[:upper:]')

  echo "ARCHIVE-${prjct}" >&2

  echo "" >&2
fi

# print elapsed time for intermediate steps

PrintTime() {

  if [ "$1" = true ] && [ -n "$3" ]
  then
    echo "$2 $3 seconds" >&2
  fi
}

function PrintTimeForEachStep() {

  PrintTime "$datafiles" "DAT" "$DAT"
  PrintTime "$download" "DWN" "$DWN"
  PrintTime "$generate" "GEN" "$GEN"
  PrintTime "$populate" "POP" "$POP"

  PrintTime "$e2index" "IDX" "$IDX"
  PrintTime "$e2invert" "INV" "$INV"
  PrintTime "$e2collect" "COL" "$COL"
  PrintTime "$e2merge" "MRG" "$MRG"
  PrintTime "$e2post" "PST" "$PST"
}

function PrintTotalElapsedTime {

  local L=$1
  local T=$2
  local D=$((T/60/60/24))
  local H=$((T/60/60%24))
  local M=$((T/60%60))
  local S=$((T%60))
  printf '%s %d second' "$L" $T 1>&2
  (( $T > 1 )) && printf 's' 1>&2
  if [ "$T" -gt 59 ]
  then
    printf ', or' 1>&2
    (( $D > 0 )) && printf ' %d day' $D 1>&2
    (( $D > 1 )) && printf 's' 1>&2
    (( $H > 0 )) && printf ' %d hour' $H 1>&2
    (( $H > 1 )) && printf 's' 1>&2
    (( $M > 0 )) && printf ' %d minute' $M 1>&2
    (( $M > 1 )) && printf 's' 1>&2
    (( $S > 0 )) && printf ' %d second' $S 1>&2
    (( $S > 1 )) && printf 's' 1>&2
  fi
  printf '\n' 1>&2
}

PrintTimeForEachStep

total_end=$(date "+%s")
total=$((total_end - total_start))
TOT=$total

if [ -z "$step" ]
then
  PrintTotalElapsedTime "TOT" "$TOT"
fi

echo "" >&2

date >&2
echo "" >&2
